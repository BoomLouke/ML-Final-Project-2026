{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrkruz9EZpRl2QZ0CIymAp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BoomLouke/ML-Final-Project-2026/blob/main/1_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Final Project 2026 - Preprocessing\n",
        "This file contains the preprocessing of the data. Throughout this file I will comment on what has been done in order to keep this document structured."
      ],
      "metadata": {
        "id": "NCw8vi4IHhXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Loading in packages and data"
      ],
      "metadata": {
        "id": "pS5KkYzgIHMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages:"
      ],
      "metadata": {
        "id": "LeQv1Zs_Iws6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "H5k2cxyVWyst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data:\n"
      ],
      "metadata": {
        "id": "SIb5Kn4FIzXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"mteb/emotion\")"
      ],
      "metadata": {
        "id": "0-80x4h_Y7lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First look into data (splits, size, etc.)"
      ],
      "metadata": {
        "id": "tYuBUqt6I27L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DATASET OVERVIEW\")\n",
        "\n",
        "# Dataset sizes\n",
        "print(f\"\\nTrain size: {len(dataset['train'])}\")\n",
        "print(f\"Validation size: {len(dataset['validation'])}\")\n",
        "print(f\"Test size: {len(dataset['test'])}\")\n",
        "\n",
        "# Get unique label mappings from the data itself\n",
        "print(\"\\n LABEL MAPPING\")\n",
        "train_df = pd.DataFrame(dataset['train'])\n",
        "label_mapping = train_df[['label', 'label_text']].drop_duplicates().sort_values('label')\n",
        "print(label_mapping.to_string(index=False))\n",
        "\n",
        "# Class distribution\n",
        "print(\"CLASS DISTRIBUTION\")\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    print(f\"\\n{split.upper()}:\")\n",
        "    split_df = pd.DataFrame(dataset[split])\n",
        "    dist = split_df['label_text'].value_counts()\n",
        "    print(dist)\n",
        "\n",
        "# Sample texts for each emotion\n",
        "print(\"SAMPLE TEXTS (one per emotion)\")\n",
        "for emotion in train_df['label_text'].unique():\n",
        "    sample = train_df[train_df['label_text'] == emotion].iloc[0]['text']\n",
        "    print(f\"\\n{emotion.upper()}: {sample}\")\n",
        "\n",
        "# Text length statistics\n",
        "print(\"TEXT LENGTH STATISTICS\")\n",
        "train_df['text_length'] = train_df['text'].str.len()\n",
        "print(train_df['text_length'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLoc3L-baeKT",
        "outputId": "f3b55796-ae37-4275-e8e1-82468e648616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET OVERVIEW\n",
            "\n",
            "Train size: 15956\n",
            "Validation size: 1988\n",
            "Test size: 1986\n",
            "\n",
            " LABEL MAPPING\n",
            " label label_text\n",
            "     0    sadness\n",
            "     1        joy\n",
            "     2       love\n",
            "     3      anger\n",
            "     4       fear\n",
            "     5   surprise\n",
            "CLASS DISTRIBUTION\n",
            "\n",
            "TRAIN:\n",
            "label_text\n",
            "joy         5345\n",
            "sadness     4663\n",
            "anger       2152\n",
            "fear        1931\n",
            "love        1297\n",
            "surprise     568\n",
            "Name: count, dtype: int64\n",
            "\n",
            "VALIDATION:\n",
            "label_text\n",
            "joy         700\n",
            "sadness     550\n",
            "anger       274\n",
            "fear        211\n",
            "love        173\n",
            "surprise     80\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TEST:\n",
            "label_text\n",
            "joy         688\n",
            "sadness     579\n",
            "anger       274\n",
            "fear        224\n",
            "love        156\n",
            "surprise     65\n",
            "Name: count, dtype: int64\n",
            "SAMPLE TEXTS (one per emotion)\n",
            "\n",
            "SADNESS: i didnt feel humiliated\n",
            "\n",
            "ANGER: im grabbing a minute to post i feel greedy wrong\n",
            "\n",
            "LOVE: i am ever feeling nostalgic about the fireplace i will know that it is still on the property\n",
            "\n",
            "SURPRISE: ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny\n",
            "\n",
            "FEAR: i feel as confused about life as a teenager or as jaded as a year old man\n",
            "\n",
            "JOY: i have been with petronas for years i feel that petronas has performed well and made a huge profit\n",
            "TEXT LENGTH STATISTICS\n",
            "count    15956.000000\n",
            "mean        96.927739\n",
            "std         55.912086\n",
            "min         11.000000\n",
            "25%         54.000000\n",
            "50%         86.000000\n",
            "75%        129.000000\n",
            "max        300.000000\n",
            "Name: text_length, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preprocessing Data"
      ],
      "metadata": {
        "id": "c4BzkYBjvhsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first make a directory for the preprocessed data."
      ],
      "metadata": {
        "id": "M4G2xi2vxgj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "SAVE_PATH = '/content/drive/MyDrive/ML-Final-Project/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ4RwRMLLoHL",
        "outputId": "bc91c1ca-88e0-4760-a293-ded4c7721c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(f'{SAVE_PATH}/preprocessed_minimal', exist_ok=True)\n",
        "os.makedirs(f'{SAVE_PATH}/preprocessed_extensive', exist_ok=True)"
      ],
      "metadata": {
        "id": "wpZkQ6nBbMEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing data for emotion detection (extensive is for classical machine learning while, minimal is for BERT)\n"
      ],
      "metadata": {
        "id": "5OGNKXuixYnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, extensive=False):\n",
        "  #general preprocessing: lowering text, removing URLs, username mentions & extra whitespaces.\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    if extensive:\n",
        "        text = re.sub(r'[^a-zA-Z\\s!?.]', '', text)\n",
        "    else:\n",
        "        text = re.sub(r'([!?.]){2,}', r'\\1', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def create_preprocessed_dataset(dataset, extensive=False):\n",
        "    processed = {}\n",
        "\n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        df = pd.DataFrame(dataset[split])\n",
        "        df['text_original'] = df['text']\n",
        "        df['text'] = df['text'].apply(lambda x: preprocess_text(x, extensive))\n",
        "\n",
        "        initial_len = len(df)\n",
        "        df = df[df['text'].str.len() > 0]\n",
        "        removed = initial_len - len(df)\n",
        "\n",
        "        processed[split] = df\n",
        "        print(f\"{split}: {len(df)} samples (removed {removed} empty)\")\n",
        "\n",
        "    return processed\n",
        "\n",
        "\n",
        "preprocessed_minimal = create_preprocessed_dataset(dataset, extensive=False)\n",
        "preprocessed_extensive = create_preprocessed_dataset(dataset, extensive=True)\n",
        "\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    minimal_path = f'{SAVE_PATH}/preprocessed_minimal/{split}.csv'\n",
        "    preprocessed_minimal[split].to_csv(minimal_path, index=False)\n",
        "    print(f\"Saved: {minimal_path}\")\n",
        "\n",
        "    extensive_path = f'{SAVE_PATH}/preprocessed_extensive/{split}.csv'\n",
        "    preprocessed_extensive[split].to_csv(extensive_path, index=False)\n",
        "    print(f\"Saved: {extensive_path}\")\n",
        "\n",
        "print(\"Preprocessing complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QooVsz3QxkM0",
        "outputId": "709ccc79-3765-47f4-dbf9-a39fc8e0a7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 15956 samples (removed 0 empty)\n",
            "validation: 1988 samples (removed 0 empty)\n",
            "test: 1986 samples (removed 0 empty)\n",
            "train: 15956 samples (removed 0 empty)\n",
            "validation: 1988 samples (removed 0 empty)\n",
            "test: 1986 samples (removed 0 empty)\n",
            "Saved: /content/drive/MyDrive/ML-Final-Project/data/preprocessed_minimal/train.csv\n",
            "Saved: /content/drive/MyDrive/ML-Final-Project/data/preprocessed_extensive/train.csv\n",
            "Saved: /content/drive/MyDrive/ML-Final-Project/data/preprocessed_minimal/validation.csv\n",
            "Saved: /content/drive/MyDrive/ML-Final-Project/data/preprocessed_extensive/validation.csv\n",
            "Saved: /content/drive/MyDrive/ML-Final-Project/data/preprocessed_minimal/test.csv\n",
            "Saved: /content/drive/MyDrive/ML-Final-Project/data/preprocessed_extensive/test.csv\n",
            "Preprocessing complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jX3JUoMMeLW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}